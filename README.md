# AmanbayTechTask
Testual task from AmanbayTech company aimed to validate the skills and depth of understanding

# ğŸ—£ï¸ Whisper CLI Inference

This project provides a simple CLI to transcribe speech from an audio file using a modified and optimized Whisper v3 model.

## ğŸ“ Project Structure

.
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # Entry point for inference
â”‚ â”œâ”€â”€ utils.py # Audio preprocessing utilities
â”‚ â”œâ”€â”€ main_utils.py # Model loading and inference logic
â”‚ â”œâ”€â”€ configs.py # Configuration (model path, device, etc.)
â”œâ”€â”€ model/ # Folder where model will be downloaded (automatically created)
â”œâ”€â”€ output/ # Folder where inference output will be saved (automatically created)


## âš™ï¸ Requirements

Install the required dependencies:

```bash
pip install -r requirements.txt

    Note: Make sure ffmpeg is installed for audio processing if not already available.

â–¶ï¸ How to Run

Run the inference script from the root of your project:

python3 app/main.py \
  --audio_file_path path/to/your_audio.wav \
  --max_token_sequence 50

Arguments

    --audio_file_path: (Required) Path to the input audio file (e.g., .wav, .flac).

    --max_token_sequence: (Optional) Maximum number of decoding steps (default: 50).
    Acceptable range is 1 to 100.

Example

python3 app/main.py \
  --audio_file_path audio_samples/english_sample.wav \
  --max_token_sequence 75

ğŸ“¤ Output

The transcribed text is saved as a .csv file in the output/ directory.
